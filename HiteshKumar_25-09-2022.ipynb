{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373b261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "import os\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddd832",
   "metadata": {},
   "source": [
    "# loading the data for Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487ef20b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Downloads/bank_marketing_part1_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDownloads/bank_marketing_part1_Data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data1\u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Downloads/bank_marketing_part1_Data.csv'"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('Downloads/bank_marketing_part1_Data.csv')\n",
    "data1= data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f100bead",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974114a",
   "metadata": {},
   "source": [
    "# 1.1 Read the data, do the necessary initial steps, and exploratory data analysis (Univariate, Bi-variate, and multivariate analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba66319",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457cf12",
   "metadata": {},
   "source": [
    " we have seen that there is no missing value, duplicate present in the data & data type is also correct.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf8c25",
   "metadata": {},
   "source": [
    "Checking dataset for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd488ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,25))\n",
    "feature_list = data.columns\n",
    "for i in range(len(feature_list)):\n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    sns.boxplot(y = data[feature_list[i]], data = data)\n",
    "    plt.title('Boxplot of {}'.format(feature_list[i]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0123c3",
   "metadata": {},
   "source": [
    "We can see that outliers present in the data and it has to be treated as clustering results are affected by the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef97e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(col):\n",
    "    sorted(col)\n",
    "    Q1,Q3=np.percentile(col,[25,75])\n",
    "    IQR=Q3-Q1\n",
    "    lower_range= Q1-(1.5 * IQR)\n",
    "    upper_range= Q3+(1.5 * IQR)\n",
    "    return lower_range, upper_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the lower range and upper range for the variable 'probability_of_full_payment'\n",
    "lr,ur=remove_outlier(data['probability_of_full_payment'])\n",
    "print(\"lower range\",lr, \"and upper range\", ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cadbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['probability_of_full_payment']=np.where(data['probability_of_full_payment']>ur,ur,data['probability_of_full_payment'])\n",
    "data['probability_of_full_payment']=np.where(data['probability_of_full_payment']<lr,lr,data['probability_of_full_payment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the lower range and upper range for the variable 'min_payment_amt'\n",
    "lr2,ur2=remove_outlier(data['min_payment_amt'])\n",
    "print(\"lower range\",lr2, \"and upper range\", ur2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_payment_amt']=np.where(data['min_payment_amt']>ur2,ur2,data['min_payment_amt'])\n",
    "data['min_payment_amt']=np.where(data['min_payment_amt']<lr2,lr2,data['min_payment_amt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "feature_list = data.columns\n",
    "for i in range(len(feature_list)):\n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    sns.boxplot(y = data[feature_list[i]], data = data)\n",
    "    plt.title('Boxplot of {}'.format(feature_list[i]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab2f73",
   "metadata": {},
   "source": [
    "we can see now there is no outliers present in the data as have treated the outliers ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c96faa",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4accf88",
   "metadata": {},
   "source": [
    "We don't have any categorical variables present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba7bfe",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79a23e",
   "metadata": {},
   "source": [
    "Non visual representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8506346",
   "metadata": {},
   "source": [
    "In our data we have no object data type so using describe function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457f983",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012d623",
   "metadata": {},
   "source": [
    "Average spending made by the customer is 14.84*1000 = 14,840Rs and highest spending is 21,180Rs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2efd97",
   "metadata": {},
   "source": [
    "minimum spending in single shopping is 4510Rs and maximum is 6550Rs so we can say that in single shopping customer spending good amount compare to maximum spending as different is not too much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3849cc0",
   "metadata": {},
   "source": [
    "Maimum sanctioned credit limit given to customer by bank is Rs 40,300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384aa031",
   "metadata": {},
   "source": [
    "Visual representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df267a35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=7,ncols=2)\n",
    "fig.set_size_inches(10,25)\n",
    "sns.histplot(data['spending'], kde=True, ax=axes[0][0])\n",
    "sns.boxplot(x='spending', data=data, ax=axes[0][1])\n",
    "sns.histplot(data['advance_payments'] , kde=True, ax=axes[1][0])\n",
    "sns.boxplot(x='advance_payments', data=data , ax=axes[1][1])\n",
    "sns.histplot(data['probability_of_full_payment'] , kde=True, ax=axes[2][0])\n",
    "sns.boxplot(x='probability_of_full_payment', data=data , ax=axes[2][1])\n",
    "sns.histplot(data['current_balance'] , kde=True, ax=axes[3][0])\n",
    "sns.boxplot(x='current_balance', data=data , ax=axes[3][1])\n",
    "sns.histplot(data['credit_limit'] , kde=True, ax=axes[4][0])\n",
    "sns.boxplot(x='credit_limit', data=data , ax=axes[4][1])\n",
    "sns.histplot(data['min_payment_amt'] , kde=True, ax=axes[5][0])\n",
    "sns.boxplot(x='min_payment_amt', data=data , ax=axes[5][1])\n",
    "sns.histplot(data['max_spent_in_single_shopping'] , kde=True, ax=axes[6][0])\n",
    "sns.boxplot(x='max_spent_in_single_shopping', data=data , ax=axes[6][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc150804",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b2a0db",
   "metadata": {},
   "source": [
    "From the above box plots we can say that there is no ouliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627c4b0",
   "metadata": {},
   "source": [
    "From above figure, we can say that for variables 'probability_of_full_payment' distribution is slightly left tailed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc0a8a",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15922eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['credit_limit'],data['advance_payments'])\n",
    "plt.xlabel('credit_limit');\n",
    "plt.ylabel('advance_payments');\n",
    "plt.title('scatter plot');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353869fc",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de2710",
   "metadata": {},
   "source": [
    "we can see that both 'credit_limit' & 'advance_payments' are highly correlated that means those who have higher credit limit are suppose to pay in advance before bill gets generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb648445",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['spending'],data['credit_limit'])\n",
    "plt.xlabel('spending');\n",
    "plt.ylabel('credit_limit');\n",
    "plt.title('scatter plot');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c5d9f",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9d693",
   "metadata": {},
   "source": [
    "We can see that higher the credit limit means higher the spending ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['probability_of_full_payment'], data['credit_limit'])\n",
    "plt.xlabel('probability_of_full_payment');\n",
    "plt.ylabel('credit_limit');\n",
    "plt.title('scatter plot');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee859a",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc895c2",
   "metadata": {},
   "source": [
    "We can see that those who have higher credit limit are expected to pay full amount and therefore Credit limit seems to be a very important parameter which is obvious because credit limit assigned based on the customer transaction and relation with bank.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26be37",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20));\n",
    "sns.pairplot(data);\n",
    "plt.title('pairplot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),annot=True,fmt=\".2f\");\n",
    "plt.title('Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748a26f",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27f690",
   "metadata": {},
   "source": [
    "variable min_payment_amt has weak correlation with other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a3224",
   "metadata": {},
   "source": [
    "varibale spending has strong correlation with other variables expect min_payment_amt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac89d6",
   "metadata": {},
   "source": [
    "Variable 'spending' is highly corrrelated to advance_payments which indicate that when customer spent high amount while shopping he also make advance payment before bill gets generated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee5d42",
   "metadata": {},
   "source": [
    "# 1.2  Do you think scaling is necessary for clustering in this case? Justify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7fea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d109c",
   "metadata": {},
   "source": [
    "We can see that mean, std and median is not same for all features so if we go without scaling then one of the feature will have higher impact on our final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52b9cb",
   "metadata": {},
   "source": [
    "From above output we can see that in our data there is a difference in the magnitude of the values therefore we need to bring the variables on the same scale and hierarchical clustering methos used distance based computation so scaling is required so that all features have same weightage ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1ad6c",
   "metadata": {},
   "source": [
    "we are using standrdscaler which applied z score and bring mean to 0 and standard deviation to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale_data = pd.DataFrame(X.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scale_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecef44",
   "metadata": {},
   "source": [
    "We have successfully scaled the data and now this data can be used for our clustering technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1a0df",
   "metadata": {},
   "source": [
    "# 1.3 Apply hierarchical clustering to scaled data. Identify the number of optimum clusters using Dendrogram and briefly describe them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wardlink= linkage(Scale_data, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend=dendrogram(wardlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0b295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dend=dendrogram(wardlink,truncate_mode='lastp',p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avglink= linkage(Scale_data, method='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend=dendrogram(avglink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f938a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend=dendrogram(avglink,truncate_mode='lastp',p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d736872",
   "metadata": {},
   "outputs": [],
   "source": [
    "centlink= linkage(Scale_data, method='centroid')\n",
    "dend=dendrogram(centlink,truncate_mode='lastp',p=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "complink= linkage(Scale_data, method='complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625821d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend=dendrogram(complink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dend=dendrogram(complink,truncate_mode='lastp',p=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4591c6f2",
   "metadata": {},
   "source": [
    "From above dendrograms with different linkage method we can see that dendrograms with method centroid giving 3 data points in 1 one of the cluster so that is not useful similarly in complete linkage method 1 cluster having 12 dats points so these are not useful methos here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c75a88",
   "metadata": {},
   "source": [
    "In dendrograms obtained from ward linkage method we can form 3 number of cluster after cutting the dendrograms as it cover maximum distance from 2 to 3 cluster so we will perform fcluster by using 3 number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters  = fcluster(wardlink, 3, criterion='maxclust')\n",
    "clusters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0495779",
   "metadata": {},
   "source": [
    "Appending Clusters to the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Fclusters'] = clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f702a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this file with Fcluster column \n",
    "data1.to_csv('Fclusters.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7ab49",
   "metadata": {},
   "source": [
    "# 1.4 Apply K-Means clustering on scaled data and determine optimum clusters. Apply elbow curve and silhouette score. Explain the results properly. Interpret and write inferences on the finalized clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b664693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9d363",
   "metadata": {},
   "source": [
    "### Creating Clusters using KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd16ddf",
   "metadata": {},
   "source": [
    "Forming 2 Clusters with K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.fit(Scale_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de59d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.inertia_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b29b9f",
   "metadata": {},
   "source": [
    "Forming clusters with K = 1,3,4,5,6 and comparing the WSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca456e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 1,random_state=1)\n",
    "k_means.fit(Scale_data)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 3,random_state=1)\n",
    "k_means.fit(Scale_data)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3822d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 4,random_state=1)\n",
    "k_means.fit(Scale_data)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8070b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 5,random_state=1)\n",
    "k_means.fit(Scale_data)\n",
    "k_means.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a12a30",
   "metadata": {},
   "source": [
    "we can see that WSS reduces as K keeps increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b2a8d",
   "metadata": {},
   "source": [
    "### Calculating WSS for other values of K - Elbow Method¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4496f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wss =[] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    KM = KMeans(n_clusters=i,random_state=1)\n",
    "    KM.fit(Scale_data)\n",
    "    wss.append(KM.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57864546",
   "metadata": {},
   "outputs": [],
   "source": [
    "wss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_clusters =[1,2,3,4,5,6,7,8,9,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5954e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N_clusters, wss)\n",
    "plt.title('Elbow curve')\n",
    "plt.xlabel('Number of clusters')                      \n",
    "plt.ylabel('Within Cluster Sum of Squares (WCSS)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb0407",
   "metadata": {},
   "source": [
    "from abobe graph we can see that Wss is not dropping significantly after cluster 3 so we can go with 3 optimum clusters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6eddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means1 = KMeans(n_clusters = 3,random_state=1)\n",
    "k_means1.fit(Scale_data)\n",
    "labels3 = k_means1.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00154cfb",
   "metadata": {},
   "source": [
    "Cluster evaluation for 3 & 4 clusters: the silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(Scale_data,labels3,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters = 4,random_state=1)\n",
    "k_means.fit(Scale_data)\n",
    "labels4 = k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12124fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(Scale_data,labels4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f594a",
   "metadata": {},
   "source": [
    "silhouette score is better for 3 clusters than for 4 clusters. So, final clusters will be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f63165",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KMeans(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer=KElbowVisualizer(model, K=(2,11),metric='silhouette')\n",
    "visualizer.fit(Scale_data)\n",
    "visualizer.poof();\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8eced2",
   "metadata": {},
   "source": [
    "from Above elbow graph we can see silhouette score for all clusters and according to it 2 is the best cluster for this data but 2 cluster does not make any sense to the business therefore we will go with 3 clusters as silhouette score is better in cluster 3 than cluster 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e25e2e1",
   "metadata": {},
   "source": [
    "Appending Clusters to the original dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Clus_kmeans4\"] =labels3\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd364f78",
   "metadata": {},
   "source": [
    "# 1.5 Describe cluster profiles for the clusters defined. Recommend different promotional strategies for different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c653da38",
   "metadata": {},
   "source": [
    "### Cluster Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0ba0b",
   "metadata": {},
   "source": [
    "First we will talk about clusters obtained  from hierarchical clustering ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Fclusters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f9363",
   "metadata": {},
   "source": [
    "So, we have identified 3 optimum clusters using Dendrogram where cluster 3 has maximum 73 data points and cluster 1 has second highest 70 data points and cluster 2 has remaining 67 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.groupby('Fclusters').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e423c",
   "metadata": {},
   "source": [
    "Cluster 1: Highest spending customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cead87",
   "metadata": {},
   "source": [
    "Cluster 2: lowest spending customers but spending in single shopping is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dd83a",
   "metadata": {},
   "source": [
    "Cluster 3: moderate spending customers with high probaility of paying full payment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f21466",
   "metadata": {},
   "source": [
    "### Recommendations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f22d5d",
   "metadata": {},
   "source": [
    "we can see that in cluster 2 where 67 customer spent very less and there probability_of_full_payment is also low but there spending in single shopping is good despite having low credit limit so bank can give credit limit increase offers to around 13 customers who have probability_of_full_payment between 86-88% & out of 67 customers 9 customers have probability_of_full_payment between 81-82% so bank should focus more on these customers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797718c6",
   "metadata": {},
   "source": [
    "In cluster 1, 70 customer is the part of this cluster and their credit card usage is quite good as they have spent 83% of their credit card limit so bank can offer credit card limit increase OR other credit cards to these customers as offering loan to these customers won't make much difference as they already have a high balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86292f24",
   "metadata": {},
   "source": [
    "In cluster 3 majority of the customer falls in this group and they spent moderate amount in shopping but their probability of paying full payment is good so bank can give some offer to these customers which lead customer to more spending may be card they are using don't have much offers and discount so bank can look into this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7a7a7",
   "metadata": {},
   "source": [
    "In clusters 2 customers despite having low credit limit spending good amont in single shopping that means these customers use crdit card more in certain situation like festival or any sell, discount etc. giving loan to these customers can also be a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a309e5",
   "metadata": {},
   "source": [
    "### Cluster profile for KMeans clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clus_kmeans4'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fdc1e6",
   "metadata": {},
   "source": [
    "So we have identify 3 optimum clusters using KMeans where 1 cluster has maximum 72 data ponits and second cluster has second highest data points and 3rd cluster has remaining data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Clus_kmeans4').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501a2f5",
   "metadata": {},
   "source": [
    " As we can see that there is no difference in the mean of varibles from Fclusters to Clus_kmeans4 as number of cluster is same 3 so we can go with same Recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3581f7",
   "metadata": {},
   "source": [
    "By using scatter plot Visualisng Fclusters that how exactly it formed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Scale_data['spending'], Scale_data['current_balance'],c =data1['Fclusters'], cmap='viridis')\n",
    "plt.title('scatter_plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed5963",
   "metadata": {},
   "source": [
    "> we can see that 3 cluster formed in the graph which we obtained in hierarchical clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa393bc",
   "metadata": {},
   "source": [
    "KMeans clusters visialization by using scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094eb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "Center=k_means1.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77034ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Scale_data['spending'], Scale_data['credit_limit'],c=data['Clus_kmeans4'], cmap='viridis')\n",
    "plt.scatter(Center[:,0],Center[:,4], c='black', s=200, alpha=1)\n",
    "plt.title('scatter_plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9caf685",
   "metadata": {},
   "source": [
    "we can see that 3 cluster formed in the graph which we obtained in KMeans clustering and dark black circle is centroid of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa65e7",
   "metadata": {},
   "source": [
    "# loading the data for Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506dec7d",
   "metadata": {},
   "source": [
    "## 2.1 Read the data, do the necessary initial steps, and exploratory data analysis (Univariate, Bi-variate, and multivariate analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4c83eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'downloads/insurance_part2_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdownloads/insurance_part2_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'downloads/insurance_part2_data.csv'"
     ]
    }
   ],
   "source": [
    "data2 = pd.read_csv('downloads/insurance_part2_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0289e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4af938",
   "metadata": {},
   "outputs": [],
   "source": [
    " data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b81ab4",
   "metadata": {},
   "source": [
    "Data types looks okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f01a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f840c3",
   "metadata": {},
   "source": [
    "Although there are duplicate values present in the data but im not removing these because there is no customer ID or any unique Id mentioned so these can be the different customers like same plan can be given to the other customer and we don't have any ID, unique number so can not remove these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d53016",
   "metadata": {},
   "source": [
    "we have seen minimum tour duration is -1 which is not correct and even 0 is also not correct why company will give insurance for 0 days in any plan it means no plan given so we need to compute these values and we are replacing with nearest value 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e3220",
   "metadata": {},
   "source": [
    "### replacing the anomalies in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Duration']= data2['Duration'].replace(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598457cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Duration']= data2['Duration'].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ffe4b",
   "metadata": {},
   "source": [
    "we have sucessfully replace the anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d831a",
   "metadata": {},
   "source": [
    "Checking unique values for categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae40a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2['Agency_Code'].unique())\n",
    "print(data2['Type'].unique())\n",
    "print(data2['Claimed'].unique())\n",
    "print(data2['Channel'].unique())\n",
    "print(data2['Product Name'].unique())\n",
    "print(data2['Destination'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb512885",
   "metadata": {},
   "source": [
    "Checking dataset for outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38117583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sns.boxplot(data2['Age']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dae971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sns.boxplot(data2['Commision']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbff08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sns.boxplot(data2['Duration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1facc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sns.boxplot(data2['Sales']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d1e2f",
   "metadata": {},
   "source": [
    "We can see that outliers present in the data for now we are not treating the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7731fe",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da462750",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caeaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e105f148",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ec737",
   "metadata": {},
   "source": [
    "50% of the customer's age is less than 36 and maximum age is 84 and average age is 38."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc81e7d",
   "metadata": {},
   "source": [
    "Average duration of the tour is 70 and minimum age duration offer by company is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c4de8",
   "metadata": {},
   "source": [
    "commision & Sales- mean and median varies signficantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac316b",
   "metadata": {},
   "source": [
    "Visual representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1811cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4,ncols=2)\n",
    "fig.set_size_inches(15,13)\n",
    "sns.histplot(data2['Age'], kde=True, ax=axes[0][0])\n",
    "sns.boxplot(x='Age', data=data2, ax=axes[0][1])\n",
    "sns.histplot(data2['Commision'] , kde=True, ax=axes[1][0])\n",
    "sns.boxplot(x='Commision', data=data2 , ax=axes[1][1])\n",
    "sns.histplot(data2['Duration'] , kde=True, ax=axes[2][0])\n",
    "sns.boxplot(x='Duration', data=data2 , ax=axes[2][1])\n",
    "sns.histplot(data2['Sales'] , kde=True, ax=axes[3][0])\n",
    "sns.boxplot(x='Sales', data=data2 , ax=axes[3][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14811619",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aaff3c",
   "metadata": {},
   "source": [
    "We can that outliers present in the data for all continuoes variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ba77e",
   "metadata": {},
   "source": [
    "Almost symmetric distributions observed for column 'Age'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03c72c",
   "metadata": {},
   "source": [
    "Apart from variable 'Age' all 3 variable showing distribution of data is skewed to the Right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5f0b8",
   "metadata": {},
   "source": [
    "##### For Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a13644",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x = 'Agency_Code')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b28a4d",
   "metadata": {},
   "source": [
    "Maximum Agency code 'EPX' assigned to the customers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x = 'Type')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e1639",
   "metadata": {},
   "source": [
    "Travel Agency is the most Type of tour insurance firms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x = 'Claimed')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b771b6",
   "metadata": {},
   "source": [
    "Almost half of the customer submitting claims which is a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x = 'Channel')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c1297",
   "metadata": {},
   "source": [
    "mostly insurance distribution is throguh online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a356d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data = data2, x = 'Product Name')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4aa3f7",
   "metadata": {},
   "source": [
    "Most popular plan is Customised Plan and Gold plan is not so famous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x = 'Destination')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab0a99",
   "metadata": {},
   "source": [
    "Most of the customer prefer their destination as Asia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c897763",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x ='Claimed',hue ='Product Name')\n",
    "plt.title('countplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f97c2b",
   "metadata": {},
   "source": [
    "Customer who has silver plan are the most who submitting claims so they might be not happy with the benefits offered within plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = data2, x ='Claimed',hue ='Type')\n",
    "plt.title('countplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0d926",
   "metadata": {},
   "source": [
    "Airlines has minimum number in terms of tour insurance firms In spite of that most of the customer who submitting claims belongs to type travel agency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = data2, x='Age',y='Product Name', hue='Destination')\n",
    "plt.title('boxplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9fc1f",
   "metadata": {},
   "source": [
    "Cancellation plan only choosen by the customer whos age is more than 18 and in silver plan there is only 1 customer whos destination is EUROPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787bd09a",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1352e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20));\n",
    "sns.pairplot(data2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eccc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data2.corr(),annot=True,fmt=\".2f\");\n",
    "plt.title('Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb18892",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c1fe0",
   "metadata": {},
   "source": [
    "Based on the heatmap there is no negative relation found between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01476810",
   "metadata": {},
   "source": [
    "Comission is highly correlated to sales as Commission is in percentage of sales so hiher the sales means higher the comission. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea88c01",
   "metadata": {},
   "source": [
    "Age has weak correlation with other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f60ae",
   "metadata": {},
   "source": [
    "# 2.2 Data Split: Split the data into test and train, build classification model CART, Random Forest, Artificial Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3ed6c",
   "metadata": {},
   "source": [
    "We need to convert Object data type into categorical/numerical data to fit in the models and we are using encoding technique as (pd.categorical().codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc44d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in data2.columns: \n",
    "    if data2[feature].dtype == 'object': \n",
    "        print('\\n')\n",
    "        print('feature:',feature)\n",
    "        print(pd.Categorical(data2[feature].unique()))\n",
    "        print(pd.Categorical(data2[feature].unique()).codes)\n",
    "        data2[feature] = pd.Categorical(data2[feature]).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8998a",
   "metadata": {},
   "source": [
    "#### Proportion of 1s and 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fe4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Claimed'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80448a95",
   "metadata": {},
   "source": [
    "We have converted all object date type into numerical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97581a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8620afec",
   "metadata": {},
   "source": [
    "Extracting the target column into separate vectors for training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2.drop(\"Claimed\", axis=1)\n",
    "Y = data2.pop(\"Claimed\")\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf82a3c",
   "metadata": {},
   "source": [
    "Splitting data into training and test set with 30% random value assinging to the test and remaining 70% is to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.30, random_state=1, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825da67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train',X_train.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('Y_train',Y_train.shape)\n",
    "print('Y_test',Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929241cb",
   "metadata": {},
   "source": [
    "## Building a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion = 'gini', random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3771de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "train_char_label = ['No', 'Yes']\n",
    "ld_Tree_File = open('ld_Tree_File.dot','w')\n",
    "dot_data = tree.export_graphviz(dt_model, \n",
    "                                out_file=ld_Tree_File, \n",
    "                                feature_names = list(X_train), \n",
    "                                class_names = list(train_char_label))\n",
    "\n",
    "ld_Tree_File.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528e00a",
   "metadata": {},
   "source": [
    "As per checking descion tree image on  webgraphviz website found that tree has overgrown/overfitted so we need to use Pruning to cut the decision tree from the middle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf742a",
   "metadata": {},
   "source": [
    "#### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(dt_model.feature_importances_*100, columns = [\"Imp\"], index = X_train.columns).sort_values('Imp',ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9f619",
   "metadata": {},
   "source": [
    "Variables Duration, Agency_Code, Sales, Age are the most important variable for our predection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf107707",
   "metadata": {},
   "source": [
    "#### Regularising the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19148144",
   "metadata": {},
   "source": [
    "We will use grid search to identify best parameters values for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [10,20,30,50,70,80,90],\n",
    "    'min_samples_leaf': [50,100,150,200,250,300,350], \n",
    "    'min_samples_split': [150,300,450,600,750],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid_search_dt1 = GridSearchCV(estimator = dt, param_grid = param_grid_dt, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_dt1.best_params_)\n",
    "print(grid_search_dt1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8138baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt1.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt1.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [30,40,50,60,70],\n",
    "    'min_samples_leaf': [40, 42, 44,46,48,50,52,54], \n",
    "    'min_samples_split': [150,200,240,260,280,300,350],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid_search_dt2 = GridSearchCV(estimator = dt, param_grid = param_grid_dt, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da02dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f6c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_dt2.best_params_)\n",
    "print(grid_search_dt2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt2.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc25ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt2.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3794e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [4.85, 4.90,4.95, 5.0,5.05,5.10,5.15,6,8,9,10],\n",
    "    'min_samples_leaf': [10,15,20, 21, 42, 62, 80], \n",
    "    'min_samples_split': [150, 175, 200, 210, 220, 230, 240, 250, 260, 270,300,310],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid_search_dt3 = GridSearchCV(estimator = dt, param_grid = param_grid_dt, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fadccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt3.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_dt3.best_params_)\n",
    "print(grid_search_dt3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt3.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt3.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80036ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [25,40,60,80,90,120],\n",
    "    'min_samples_leaf': [18,20,30,45,60,75,90], \n",
    "    'min_samples_split': [200, 210, 220, 230, 240, 250, 260,300,310],\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid_search_dt4 = GridSearchCV(estimator = dt, param_grid = param_grid_dt, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edfe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt4.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb93059",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_dt4.best_params_)\n",
    "print(grid_search_dt4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafbe890",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt4.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20494a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dt4.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaee0d",
   "metadata": {},
   "source": [
    "After applying grid search with multiple max_depth, min_samples_leaf, min_samples_split train, test score is not going more than 80 so we will go with the best parameters which gives us highest score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1db52",
   "metadata": {},
   "source": [
    "Best_grid_search = criterion': 'gini', 'max_depth': 4.85, 'min_samples_leaf': 10, 'min_samples_split': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b3373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dt_model = DecisionTreeClassifier(criterion = 'gini', max_depth =4.85 ,min_samples_leaf=10,min_samples_split=150)\n",
    "reg_dt_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907fe330",
   "metadata": {},
   "source": [
    "#### Generating New Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0510e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_tree_regularized = open('ld_tree_regularized.dot','w')\n",
    "dot_data = tree.export_graphviz(reg_dt_model, out_file= ld_tree_regularized , feature_names = list(X_train), class_names = list(train_char_label))\n",
    "\n",
    "ld_tree_regularized.close()\n",
    "dot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550ed1a7",
   "metadata": {},
   "source": [
    "#### Variable Importance after generating tree by using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c10b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(reg_dt_model.feature_importances_*100, columns = [\"Imp\"], index = X_train.columns).sort_values('Imp',ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e2d20",
   "metadata": {},
   "source": [
    "we can see with best parameters now important variables are only 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3432c",
   "metadata": {},
   "source": [
    "#### Predicting on Training and Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_dt = reg_dt_model.predict(X_train)\n",
    "Ytest_predict_dt = reg_dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ytrain_predict',Ytrain_predict_dt.shape)\n",
    "print('ytest_predict',Ytest_predict_dt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f00a6a",
   "metadata": {},
   "source": [
    "#### Getting the Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb53ff",
   "metadata": {},
   "source": [
    "#### Getting the Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a650568",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict_prob=reg_dt_model.predict_proba(X_test)\n",
    "Ytest_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.DataFrame(Ytest_predict_prob).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_prob=reg_dt_model.predict_proba(X_train)\n",
    "Ytrain_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06c940",
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.DataFrame(Ytrain_predict_prob).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc5f4e",
   "metadata": {},
   "source": [
    "## Building Random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827edd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be15a1",
   "metadata": {},
   "source": [
    "We will use grid search to identify best parameters values for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [7, 10],\n",
    "    'max_features': [4, 6],\n",
    "    'min_samples_leaf': [50, 100],\n",
    "    'min_samples_split': [150, 300],\n",
    "    'n_estimators': [301, 501]\n",
    "}\n",
    "\n",
    "rfcl = RandomForestClassifier(random_state=1)\n",
    "\n",
    "grid_searchrf = GridSearchCV(estimator = rfcl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searchrf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf.best_params_)\n",
    "print(grid_searchrf.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf.score(X_train,Y_train))\n",
    "print(grid_searchrf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [12,15,17],\n",
    "    'max_features': [8,9,10],\n",
    "    'min_samples_leaf': [25,50],\n",
    "    'min_samples_split': [30,60,80],\n",
    "    'n_estimators': [401,501]\n",
    "}\n",
    "\n",
    "rfcl = RandomForestClassifier(random_state=1)\n",
    "\n",
    "grid_searchrf1 = GridSearchCV(estimator = rfcl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1489db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searchrf1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abd590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf1.best_params_)\n",
    "print(grid_searchrf1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf1.score(X_train,Y_train))\n",
    "print(grid_searchrf1.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3,4,5],\n",
    "    'max_features': [4,8],\n",
    "    'min_samples_leaf': [8,9],\n",
    "    'min_samples_split': [50,46],\n",
    "    'n_estimators': [290,350]\n",
    "}\n",
    "\n",
    "rfcl = RandomForestClassifier(random_state=1)\n",
    "\n",
    "grid_searchrf2 = GridSearchCV(estimator = rfcl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4594918",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searchrf2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2008214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf2.best_params_)\n",
    "print(grid_searchrf2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_searchrf2.score(X_train,Y_train))\n",
    "print(grid_searchrf2.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafcb11",
   "metadata": {},
   "source": [
    "After applying grid search with multiple parameters train score is close to 80 so we will go with the best parameters which gives us highest score\n",
    "\n",
    "Best_grid_search = 'max_depth': 5, 'max_features': 8, 'min_samples_leaf': 8, 'min_samples_split': 46, 'n_estimators': 350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bddc63",
   "metadata": {},
   "source": [
    "#### Generating New RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac94872",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rfcl = RandomForestClassifier(n_estimators = 350,\n",
    "                                  max_features=8,\n",
    "                                  random_state=1,\n",
    "                                  max_depth= 5,\n",
    "                                  min_samples_leaf= 8,\n",
    "                                  min_samples_split=46\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rfcl.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df49f45",
   "metadata": {},
   "source": [
    "### Predicting the Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b98401",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_rfcl = reg_rfcl.predict(X_train)\n",
    "Ytest_predict_rfcl = reg_rfcl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c632a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ytrain_predict',Ytrain_predict_rfcl.shape)\n",
    "print('ytest_predict',Ytest_predict_rfcl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615b00d",
   "metadata": {},
   "source": [
    "#### Getting the Predicted Classes and Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict_rfcl\n",
    "Ytest_predict_prob_rfcl=reg_rfcl.predict_proba(X_test)\n",
    "Ytest_predict_prob_rfcl\n",
    "pd.DataFrame(Ytest_predict_prob_rfcl).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecddad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_rfcl\n",
    "Ytrain_predict_prob_rfcl=reg_rfcl.predict_proba(X_train)\n",
    "Ytrain_predict_prob_rfcl\n",
    "pd.DataFrame(Ytrain_predict_prob_rfcl).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751bd17",
   "metadata": {},
   "source": [
    "#### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303347d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(reg_rfcl.feature_importances_, \n",
    "                    columns = [\"Imp\"], \n",
    "                    index = X_train.columns).sort_values('Imp',ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6866c",
   "metadata": {},
   "source": [
    "Variables Agency_Code, Sales, Product Name are the important variables for prdection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c5919",
   "metadata": {},
   "source": [
    "## Building a Neural Network Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e9acb1",
   "metadata": {},
   "source": [
    "we have to scale the data for ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c37c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "X_trains = sc.fit_transform(X_train) \n",
    "X_tests = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [100,100,100],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'tol': [0.1,0.01],\n",
    "    'max_iter' : [10000]\n",
    "}\n",
    "\n",
    "nncl = MLPClassifier(random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = nncl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_trains,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.score(X_trains,Y_train))\n",
    "print(grid_search.score(X_tests,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [100,200,300,500],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'tol': [0.1,0.01],\n",
    "    'max_iter' : [5000,2500,6000,7000]\n",
    "}\n",
    "\n",
    "nncl = MLPClassifier(random_state=1)\n",
    "\n",
    "grid_search1 = GridSearchCV(estimator = nncl, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search1.fit(X_trains,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada27972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search1.best_params_)\n",
    "print(grid_search1.best_estimator_)\n",
    "print(grid_search1.score(X_trains,Y_train))\n",
    "print(grid_search1.score(X_tests,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332f968",
   "metadata": {},
   "source": [
    "After applying grid search with multiple parameters score is not going above 80 so we will go with the best parameters which gives us highest score\n",
    "\n",
    "Best_grid_search = 'activation': 'relu', 'hidden_layer_sizes': 500, 'max_iter': 5000, 'solver': 'adam', 'tol': 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f358ef98",
   "metadata": {},
   "source": [
    "#### Generating New ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd66668",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_nncl = MLPClassifier(hidden_layer_sizes = 500,\n",
    "                                  activation='relu',\n",
    "                                  random_state=1,\n",
    "                                  max_iter= 5000,\n",
    "                                tol= 0.01\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_nncl.fit(X_trains, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1862a",
   "metadata": {},
   "source": [
    "### Predicting the Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ab341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_ANN =reg_nncl.predict(X_trains)\n",
    "Ytest_predict_ANN = reg_nncl.predict(X_tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ytrain_predict',Ytrain_predict_ANN.shape)\n",
    "print('ytest_predict',Ytest_predict_ANN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0043a97",
   "metadata": {},
   "source": [
    "#### Getting the Predicted Classes and Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d28ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_predict_ANN\n",
    "Ytest_predict_prob_ANN =reg_nncl.predict_proba(X_tests)\n",
    "Ytest_predict_prob_ANN\n",
    "pd.DataFrame(Ytest_predict_prob_ANN).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain_predict_ANN\n",
    "Ytrain_predict_prob_ANN =reg_nncl.predict_proba(X_trains)\n",
    "Ytrain_predict_prob_ANN\n",
    "pd.DataFrame(Ytrain_predict_prob_ANN).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda1cf3f",
   "metadata": {},
   "source": [
    "NOTE: we can not get Feature importance in ANN model we can say it's a disadvantage of ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccfc56",
   "metadata": {},
   "source": [
    "# 2.3 Performance Metrics: Comment and Check the performance of Predictions on Train and Test sets using Accuracy, Confusion Matrix, Plot ROC curve and get ROC_AUC score, classification reports for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cd841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve,classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7964",
   "metadata": {},
   "source": [
    "### For CART Confusion Matrix , Classification Report, AUC and ROC for the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e01865",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_train, Ytrain_predict_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67381a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Ytrain_predict_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b998d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = reg_dt_model.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "cart_train_auc = roc_auc_score(Y_train, probs)\n",
    "print('AUC: %.3f' % cart_train_auc)\n",
    "# calculate roc curve\n",
    "cart_train_fpr, cart_train_tpr, cart_train_thresholds = roc_curve(Y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(cart_train_fpr, cart_train_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382dd1d",
   "metadata": {},
   "source": [
    "### For CART Confusion Matrix , Classification Report, AUC and ROC  for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Ytest_predict_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Ytest_predict_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = reg_dt_model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "cart_test_auc = roc_auc_score(Y_test, probs)\n",
    "print('AUC: %.3f' % cart_test_auc)\n",
    "# calculate roc curve\n",
    "cart_test_fpr, cart_test_tpr, cart_test_thresholds = roc_curve(Y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(cart_test_fpr, cart_test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3738bb",
   "metadata": {},
   "source": [
    "## Cart Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c3424",
   "metadata": {},
   "source": [
    "#### Train Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a7ffa",
   "metadata": {},
   "source": [
    "AUC- 82%\n",
    "\n",
    "Accuracy- 80%\n",
    "\n",
    "Precision- 70%\n",
    "\n",
    "f1-Score- 67%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c3f73",
   "metadata": {},
   "source": [
    "#### test Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e8bfd",
   "metadata": {},
   "source": [
    "AUC- 77%\n",
    "\n",
    "Accuracy- 77%\n",
    "\n",
    "Precision- 65%\n",
    "\n",
    "f1-Score- 61%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d1d23",
   "metadata": {},
   "source": [
    "Training and Test set results showing some changes, The Overall model performance is moderate enough to start predicting if any  customer will submit claim or not.\n",
    "\n",
    "Agency_Code, Sales is the most important variable for predicting claims."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832c8db",
   "metadata": {},
   "source": [
    "### For RF Confusion Matrix , Classification Report, AUC and ROC for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ae45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_train, Ytrain_predict_rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Ytrain_predict_rfcl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139461a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = reg_rfcl.predict_proba(X_train)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "rf_train_auc = roc_auc_score(Y_train, probs)\n",
    "print('AUC: %.3f' % rf_train_auc)\n",
    "# calculate roc curve\n",
    "rf_train_fpr, rf_train_tpr, rf_train_thresholds = roc_curve(Y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(rf_train_fpr, rf_train_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54bd83",
   "metadata": {},
   "source": [
    "### For RF Confusion Matrix , Classification Report, AUC and ROC for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00720671",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Ytest_predict_rfcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Ytest_predict_rfcl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a54c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = reg_rfcl.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "rf_test_auc = roc_auc_score(Y_test, probs)\n",
    "print('AUC: %.3f' % rf_test_auc)\n",
    "# calculate roc curve\n",
    "rf_test_fpr, rf_test_tpr, rf_test_thresholds = roc_curve(Y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(rf_test_fpr, rf_test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618aa2c0",
   "metadata": {},
   "source": [
    "### RF Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4b0dd",
   "metadata": {},
   "source": [
    "#### Train Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b430d",
   "metadata": {},
   "source": [
    "AUC- 85%\n",
    "\n",
    "Accuracy- 81%\n",
    "\n",
    "Precision- 74%\n",
    "\n",
    "f1-Score- 67%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1fbfc",
   "metadata": {},
   "source": [
    "#### test  Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5879e",
   "metadata": {},
   "source": [
    "AUC- 81%\n",
    "\n",
    "Accuracy- 77%\n",
    "\n",
    "Precision- 65%\n",
    "\n",
    "f1-Score- 58%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e7c52",
   "metadata": {},
   "source": [
    "Training and Test set results showing some changes, The Overall model performance is moderate enough to start predicting if any customer will submit claim or not.\n",
    "\n",
    "Agency_Code, Sales, Product Name are the most important variable for predicting claims."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445956a6",
   "metadata": {},
   "source": [
    "### For ANN Confusion Matrix , Classification Report, AUC and ROC for the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_train, Ytrain_predict_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05410976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Ytrain_predict_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50454c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = reg_nncl.predict_proba(X_trains)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "ann_train_auc = roc_auc_score(Y_train, probs)\n",
    "print('AUC: %.3f' % ann_train_auc)\n",
    "# calculate roc curve\n",
    "ann_train_fpr, ann_train_tpr, ann_train_thresholds = roc_curve(Y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ann_train_fpr, ann_train_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08a7e8",
   "metadata": {},
   "source": [
    "### For ANN Confusion Matrix , Classification Report, AUC and ROC for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c88ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Ytest_predict_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ae85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Ytest_predict_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6132c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = reg_nncl.predict_proba(X_tests)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "ann_test_auc = roc_auc_score(Y_test, probs)\n",
    "print('AUC: %.3f' % cart_train_auc)\n",
    "# calculate roc curve\n",
    "ann_test_fpr, ann_test_tpr, ann_test_thresholds = roc_curve(Y_test, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ann_test_fpr, ann_test_tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786c745",
   "metadata": {},
   "source": [
    "### ANN Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6ba77",
   "metadata": {},
   "source": [
    "#### Train Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf536b14",
   "metadata": {},
   "source": [
    "AUC- 82%\n",
    "\n",
    "Accuracy- 79%\n",
    "\n",
    "Precision- 69%\n",
    "\n",
    "f1-Score- 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90578023",
   "metadata": {},
   "source": [
    "#### test Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae476bf2",
   "metadata": {},
   "source": [
    "AUC- 78%\n",
    "\n",
    "Accuracy- 75%\n",
    "\n",
    "Precision- 62%\n",
    "\n",
    "f1-Score- 55%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30666a",
   "metadata": {},
   "source": [
    "# 2.4 Final Model: Compare all the models and write an inference which model is best/optimized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acad833",
   "metadata": {},
   "source": [
    "### Comparison of the performance metrics from the 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ecd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=['Accuracy', 'AUC', 'Recall','Precision','F1 Score']\n",
    "dataa = pd.DataFrame({'CART Train':[0.80,0.826,0.64,0.70,0.67],\n",
    "        'CART Test':[0.77,0.777,0.57,0.65,0.61],\n",
    "       'Random Forest Train':[0.81,0.857,0.62,0.74,0.67],\n",
    "        'Random Forest Test':[0.77,0.811,0.53,0.65,0.58],\n",
    "       'Neural Network Train':[0.79,0.824,0.57,0.69,0.62],\n",
    "        'Neural Network Test':[0.75,0.826,0.49,0.62,0.55]},index=index)\n",
    "round(dataa,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39862471",
   "metadata": {},
   "source": [
    "### ROC Curve for the 3 models on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f901b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(cart_train_fpr, cart_train_tpr,color='red',label=\"CART\")\n",
    "plt.plot(rf_train_fpr,rf_train_tpr,color='green',label=\"RF\")\n",
    "plt.plot(ann_train_fpr,ann_train_tpr,color='black',label=\"NN\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de20ba9",
   "metadata": {},
   "source": [
    "### ROC Curve for the 3 models on the test  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(cart_test_fpr, cart_test_tpr,color='red',label=\"CART\")\n",
    "plt.plot(rf_test_fpr,rf_test_tpr,color='green',label=\"RF\")\n",
    "plt.plot(ann_test_fpr,ann_test_tpr,color='black',label=\"NN\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb741b9e",
   "metadata": {},
   "source": [
    "Out of the 3 models, Random Forest has slightly better performance than the Cart and Neural network model interms of overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab338b2",
   "metadata": {},
   "source": [
    "From Cart and Random Forest Model, the variable Agency_Code, Sales is found to be the most useful feature amongst all other features for predicting if a person will submit claim or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2003054",
   "metadata": {},
   "source": [
    "# 2.5 Inference: Based on the whole Analysis, what are the business insights and recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293bf50",
   "metadata": {},
   "source": [
    "As per the data most of insurance is done by online channel Other interesting fact, is almost all the offline business has a claimed associated, need to find why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57dc2e0",
   "metadata": {},
   "source": [
    "Agency JZI need to focus more as their sales are very low . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40059e",
   "metadata": {},
   "source": [
    "there is some moderate moderate underfitting in train and test data so we can do better if we get more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005725e8",
   "metadata": {},
   "source": [
    "More sales happen through Agency than Airlines and the trend shows that submitted claims are associcated with Airline so need to check what is wrong with this firm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b758ce",
   "metadata": {},
   "source": [
    "As we have selected RF model as  final model and as per checking classification report it obtained that recall is important considering the model has failed to predict 131(FN) customers who did submit claim with a recall of 0.57,so major focus can be upon improving the recall score which can provide some insights for the company to take prior steps in analysing those customers who migh submit claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d9091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
